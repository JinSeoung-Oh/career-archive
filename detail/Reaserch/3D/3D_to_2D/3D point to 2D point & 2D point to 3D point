1) 3D → 2D 변환 조건
   -1. 필요한 것:
       - 3D point (X, Y, Z)
       - Intrinsic matrix (3×3)
         만약 calib의 intrinsic이 3×4로 주어진 경우 = Reference camera 존재
         → 마지막 열 [3][0],[3][1],[3][2] baseline parameter를 제외하고 3×3 intrinsic 따로 정의
       - Extrinsic matrix (3×4)
         [𝑅∣𝑇] 형태 = Rotation matrix 𝑅 + Translation vector 𝑇

2) 3D → 2D 계산 공식
   -1. Extrinsic 적용 (월드 → 카메라 좌표):
       |𝑋′|    |𝑋|
       |𝑌′| = 𝑅|𝑌| + 𝑇
       |𝑍′|    |𝑍|
   -2. 정규화 좌표(Normalized):
       𝑥=𝑋′/𝑍′ , 𝑦=𝑌′/𝑍′
       여기서 
       𝑍′= depth
   -3. Intrinsic 적용 (카메라 좌표 → 이미지 좌표):
       𝑢=𝑓_𝑥⋅𝑥+𝑐_𝑥, 𝑣=𝑓_𝑦⋅𝑦+𝑐_𝑦
       - 𝑓_𝑥 = intrinsic[0,0]
       - 𝑓_𝑦 = intrinsic[1,1]
       - 𝑐_𝑥 = intrinsic[0,2]
       - 𝑐_𝑦 = intrinsic[1,2]
       즉,
       (𝑢,𝑣)=𝐾⋅|𝑥 𝑦 1|^T
​
3) 코드 예시 (3D → 2D)
import numpy as np

def project_point_3d_to_2d(X, K, R, T):
    """
    X: (3,) 3D world 좌표
    K: (3,3) intrinsic
    R: (3,3) rotation
    T: (3,) translation
    return: (u,v), depth Z'
    """
    Xc = R @ X + T   # (X', Y', Z')
    x = Xc[0] / Xc[2]
    y = Xc[1] / Xc[2]

    u = K[0,0]*x + K[0,2]
    v = K[1,1]*y + K[1,2]
    return np.array([u,v]), Xc[2]

4) 2D → 3D 변환 (역순)
   - 먼저 (𝑋′,𝑌′,𝑍′)를 만들어야 함 → (𝑢,𝑣) 픽셀 좌표와 depth 𝑍가 필요.
   - 즉,
     (𝑋′,𝑌′,𝑍′)=(𝑢⋅𝑍, 𝑣⋅𝑍, 𝑍)
   - 그 다음 Extrinsic과 Intrinsic을 분해한 식을 역으로 적용:
     𝑋_𝑤=𝑅^(−1)⋅𝐾^(−1)⋅((𝑋′,𝑌′,𝑍′)−𝑇)

5) 코드 예시 (2D → 3D)
def backproject_point_2d_to_3d(u, v, Z, K, R, T):
    """
    u,v: 이미지 좌표
    Z: depth (카메라 좌표계 상)
    K: (3,3) intrinsic
    R: (3,3) rotation
    T: (3,) translation
    return: (3,) 3D world 좌표
    """
    # 정규화 좌표계로 변환
    x = (u - K[0,2]) / K[0,0]
    y = (v - K[1,2]) / K[1,1]

    # 카메라 좌표계로 확장
    Xc = np.array([x*Z, y*Z, Z])

    # 월드 좌표로 변환
    Xw = np.linalg.inv(R) @ (Xc - T)
    return Xw
