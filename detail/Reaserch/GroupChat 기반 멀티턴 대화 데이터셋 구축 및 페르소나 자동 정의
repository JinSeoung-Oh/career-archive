프로젝트명: GroupChat 기반 멀티턴 대화 데이터셋 구축 및 페르소나 자동 정의
기간: 2024년 8월

1) 목적
   -1. 2명 이상의 전문가가 특정 주제에 대해 다회차 대화를 나누는 데이터셋 필요
   -2. 단순 Chat Completions 방식은 오류 및 비자연스러운 전개 발생 → GroupChat 프레임워크로 개선

2) 구현 방법
   -1. Autogen GroupChat 구조
       - GroupChat Manager가 사회자 역할
       - 초기 Agent가 초안 생성 → 다른 Agent들이 페르소나에 맞게 수정/보완
   -2. 페르소나 자동 정의
       - MS의 Autogen 함수인 build_from_library 활용, 직무 기반 system prompt 및 description 자동 생성
       - AGENT_SYS_MSG_PROMPT, AGENT_DESC_PROMPT 기반 → JSON 파일로 저장하여 재활용
   -3. 실행 및 저장
       - Autogen의 start_task 함수 기반 대화 실행, log_message 함수로 로그 기록
       - Agent별 메시지를 JSON 포맷으로 저장

3) 결과
   -1. Multi-turn Conversation
       - 조건: 전화번호, 이메일, 일정 관련 질문 최소 1개 포함
       - Chat Completions 단독 실행 시: 부자연스러운 대화 생성
       - GroupChat 실행 시: 전문가 간 자연스럽고 일관된 대화 확보
   -2. 100턴 이상 대화
       - LLM 지식 및 토큰 한계로 중복·무의미 대화 발생
       - 안정적 한계: 약 50턴 내외 (30~80턴)
       - 100턴 이상은 분할 생성 후 수작업 연결 필요
       - GPT-4o 환각 심각 → Claude Sonnet 3.5 사용

4) Insights (무엇을 알 수 있었는가)
   -1. GroupChat의 유효성
       - 단순 Chat Completion 대비 훨씬 자연스러운 멀티턴 대화 확보 가능 → 전문가 대화 데이터셋 구축에 효과적임을 확인.
   -2. LLM 한계 인식 
       - 50턴 이상에서 반복/작화증 발생, 100턴 이상은 사실상 불가능 → 대화 길이에 따른 LLM 한계를 실험적으로 규명.
   -3. 모델별 특성
       - GPT-4o는 장문 생성 시 환각이 심각했으나, Claude Sonnet 3.5는 안정적인 결과 제공 → 모델 선택 중요성 확인.
   -4. 페르소나 자동화 효과 
       - 일관된 직무 기반 대화 생성을 가능하게 했으며, 수동 정의 대비 품질 향상과 효율성을 입증.
   -5. 데이터셋 구축 한계와 필요성
       - 100턴 이상의 대화는 현 시점 LLM만으로는 자동 연속성 확보가 어렵고, 사람이 개입해야 함을 확인 → 향후 연구 필요 포인트 도출.
