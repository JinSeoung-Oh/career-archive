Panoptic-PolarNet (CVPR 2021)

1. 모델 개요
   - 목표: 3D 포인트클라우드에서 Panoptic Segmentation (Semantic + Instance 동시 수행).
   - 특징: Proposal-free 구조로 proposal 기반 모델보다 상대적으로 빠름.

2. 접근 방식:
   - 3D 공간 직접 연산 대신 2D BEV map 상에서 주요 계산을 수행하여 속도 개선.
   - YOLO-v4의 self-adversarial pruning 기법을 후반부에 적용, 추가적인 속도 향상 달성.
   - Polar coordinate system(극좌표계) 기반 인코딩을 사용, 중심(LiDAR 위치)을 기준으로 거리·각도 표현.
   - Visibility feature는 Occupancy grid map 기반으로 해석됨.

3. 실험 과정
   - 데이터셋: SemanticKITTI dataset.
   - 결과 저장: Panoptic segmentation label을 실제 좌표와 1:1 매핑해 dictionary 형태로 저장.
   - Cluster 단위: Object 단위보다는 class 단위 cluster 진행. Instance 단위 분리에는 한계가 있었음.
   - GPU 환경: RTX 3090 단일 기준, 학습/추론에 4일 이상 소요. Multi-GPU 분산 시 단축 가능.
   - Visualization: MeshLab, vedo 등을 이용해 결과 확인. 초기에는 road만 보이는 문제 있었으나 label 매핑 수정 후 object별 색상 라벨링 가능.

4. 관찰된 문제
   - Semantic vs Instance label 간 매핑 불일치 → 색상 라벨링이 batch 단위로 어긋나는 현상 발생.
   - Panoptic 결과는 사실상 semantic segmentation과 유사하며, object-by-object로는 labeling 되지만 class annotation은 불완전.
   - 일부 클래스 혼선 발생: 자동차가 오토바이/사람 class로 잘못 labeling 되는 사례 발견.
      Human class (6번 레이블) 확인 필요 → 사람 객체가 있는 데이터에서의 레이블링 검증 필요.

5. 진행 수준
   - 테스트 및 초기 분석 완료.
   - 문제점: class annotation 불완전, 일부 label mapping 오류.
   - 차후 계획: instance–semantic label 매핑 알고리즘 개선 및 class-level annotation 보완 필요.
