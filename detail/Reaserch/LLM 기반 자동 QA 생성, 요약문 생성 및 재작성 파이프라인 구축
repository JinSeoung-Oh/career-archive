프로젝트명: LLM 기반 자동 QA 생성, 요약문 생성 및 재작성 파이프라인 구축
기간: 2024년 7월

1) 목적
   - 기존 챗봇 코드(AutoGen + LangGraph + Agent Orchestration)를 확장하여 QA/요약/재작성까지 처리 가능한 멀티테스크 파이프라인 구현.
   - 수작업 개입 최소화, 에이전트 기반 동적 Task 분석 및 실행 자동화 목표.

2) 구현 방법
   -1. 페르소나 Prompt 자동 생성
       - MS autogen의 build_from_library 활용, 각 직위(GeneralQAExpert, SummaryExpert, RewriteExpert 등)에 맞는 시스템 프롬프트 및 설명 자동 생성.
       - JSON 포맷으로 관리 → 재활용 및 확장 가능.
   -2. Agent Orchestration
       - 멀티 테스크: 쿼리를 세부 sub-task로 분할 후, 각 sub-task에 적절한 에이전트 자동 할당.
       - 싱글 테스크: 세부 쿼리 분석 생략, 단일 에이전트로 실행.
       - 자체 피드백 요청이 포함될 경우 FeedbackExpert 및 ImprovementExpert 자동 추가.
   -3. LangGraph 기반 파이프라인
       - sub-task 단위로 LangGraph 자동 생성.
       - orchestrator, route_to_agent 함수로 에이전트 라우팅 및 실행 관리.

3) 테스트 결과
   -1. QA 생성: 컨텍스트에서 10개 QA 쌍 자동 생성 (정확하고 맥락 일치).
   -2. 요약문 생성: 기사형 텍스트를 짧고 명확하게 요약.
   -3. 재작성 결과: 보고서 형식으로 변환 가능하나 일부 표현은 애매 → 재작성 페르소나 개선 필요.
   -4. 피드백 반영: "자체 피드백을 통해 향상된 결과 리턴" 요청 시, Feedback/Improvement Agent가 자동 포함되어 개선된 결과 생성.

4) To-do
   -1. 일부 에이전트 sys_prompt 개선 필요.
   -2. 재작성 에이전트 결과 품질 검토 및 개선.
   -3. 추가 조건 처리 함수 개발 (예: "음슴체로 작성").
   -4. 멀티테스크 처리 시 잠재적 오류 방지 로직 강화 예정.

5) Insights
   - 멀티테스크 파이프라인 유효성: QA, 요약, 재작성을 단일 워크플로우로 연결할 수 있음을 입증.
   - 동적 에이전트 선택 효과: Task 분석을 통한 자동 에이전트 매핑으로 유연성과 확장성을 확보.
   - 한계점 발견: 재작성 에이전트의 품질 편차, 멀티테스크 시 중복·에러 가능성 확인.
   - 피드백 기반 개선: Feedback/Improvement Agent 자동 추가 설계가 결과 품질을 실제로 향상시킴을 확인.
