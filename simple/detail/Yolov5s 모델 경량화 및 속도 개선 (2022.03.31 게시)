프로젝트명: Yolov5s 모델 경량화 및 속도 개선
기간/게시일: 2022년 3월 31일

1. 배경:  
   딥러닝 모델의 고도화는 정확도 향상을 가져왔으나, 연산 복잡도로 인해 추론 속도가 크게 저하되는 문제가 발생. 실무 환경에서는 빠른 응답성과 효율성이 요구되므로 모델 경량화와 속도 최적화 연구가 필요함.

2. 접근 방법:
   -1. ONNX 변환
       - yolov5s.pt를 ONNX 포맷으로 변환해 CPU/GPU 환경에서 성능 비교.
       - 프레임워크 간 호환성 및 최적화 가능성을 활용해 속도 개선 효과를 검증.
   -2. Pruning + Quantization
       - SparseML 활용해 불필요한 연산 제거 및 가중치 압축.
       - 변환된 모델을 DeepSparse 엔진에서 실행해 CPU 추론 성능 평가.

3. 실험 결과:
   - yolov5s.pt (GPU) 모델: 7,738장 처리 약 33분 (가장 빠른 성능).
   - yolov5s.onnx (CPU/GPU) 모델: 단일 이미지 처리 속도는 월등히 빠르나, 대규모 데이터셋 처리에서는 예상보다 큰 개선 없음.
   - Pruned/Quantized 모델: 원본 대비 성능 향상이 미미하고, DeepSparse 엔진이 리눅스 전용이라 Windows 기반 현업 환경에는 부적합.

4. 결론:
   - ONNX는 단일 이미지 처리 속도에서 유리하나, 실제 대규모 처리에서는 pt+GPU 모델이 더 효율적.
   - SparseML 기반 경량화 기법은 적용 가능성이 있으나, 플랫폼 제약 및 리소스 문제로 실용성이 낮음. 
   - 따라서, 최적화된 원본 Yolov5s GPU 모델 유지가 가장 현실적인 선택으로 판단됨.
